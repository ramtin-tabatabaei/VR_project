{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22511e53-1781-4b0d-ada0-31203fb3b454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d919ad22-670b-4033-9db0-e1464ef2fe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "tf=120\n",
    "sequence = 30\n",
    "delta = 1\n",
    "TTP = 0.8 # Train Test Percentage \n",
    "K = 3\n",
    "epoch = 100\n",
    "early = 10\n",
    "lstm1 = 64\n",
    "lstm2 = 64\n",
    "random = 0 # on=1 off=0\n",
    "KFold = 1 # on=1 off=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5a2b309-d795-44fc-b362-407edfd7e3fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'F:\\\\Courses\\\\Paper\\\\Mine\\\\Paper3\\\\Data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCourses\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPaper\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMine\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPaper3\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# get a list of all .txt files in the directory\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m txt_files \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# print the number of .txt files found\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of txt files:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(txt_files))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'F:\\\\Courses\\\\Paper\\\\Mine\\\\Paper3\\\\Data'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "directory = r\"F:\\Courses\\Paper\\Mine\\Paper3\\Data\"\n",
    "\n",
    "# get a list of all .txt files in the directory\n",
    "txt_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.txt')]\n",
    "\n",
    "# print the number of .txt files found\n",
    "print(\"Number of txt files:\", len(txt_files))\n",
    "\n",
    "# read the contents of each .txt file and store them in an array\n",
    "Data = np.zeros((len(txt_files),50000,4))\n",
    "for file_path in txt_files:\n",
    "    for i in range(len(txt_files)):\n",
    "        data = np.loadtxt(txt_files[i], dtype=object)\n",
    "        data = [line.split(',') for line in data]\n",
    "\n",
    "        # Convert the resulting list of lists to a NumPy array with the appropriate data types\n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        #data = data.astype(np.int32)\n",
    "        A = np.zeros((50000-data.shape[0], data.shape[1]))\n",
    "        Data[i] = np.concatenate((data, A))\n",
    "\n",
    "# # print the contents of the array\n",
    "# print(\"File contents:\", file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f99ce9-29c2-4157-8c9d-bcd69fb5755e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size:  2\n"
     ]
    }
   ],
   "source": [
    "if random ==1:\n",
    "    Frames = np.zeros((frames.shape[0],frames.shape[1],2),dtype='float') \n",
    "    A = np.array(range(12))\n",
    "    random.shuffle(A)\n",
    "    for i in range(12):\n",
    "        Frames[i] = frames[A[i]]\n",
    "    frames = Frames\n",
    "    \n",
    "    \n",
    "if KFold == 1:\n",
    "    \n",
    "    Size = round(len(txt_files)*(1-TTP))\n",
    "    print(\"Size: \",Size)\n",
    "    data_zeros = np.zeros((Data.shape[0], Data.shape[1], Data.shape[2]),dtype='float') \n",
    "    startpoint = (K-1)*Size\n",
    "    A = np.array(range(len(txt_files)))\n",
    "    for i in range(Size):\n",
    "        data_zeros[i] = Data[startpoint]\n",
    "        A = np.delete(A, Size*(K-1))\n",
    "        startpoint = startpoint + 1\n",
    "    for i in range(len(txt_files)-Size):\n",
    "        data_zeros[i+Size] = Data[A[i]]\n",
    "    Data = data_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888b812a-cf76-4592-a1b1-ef72dfe30009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file into a DataFrame\n",
    "df = pd.read_excel(r'F:\\Courses\\Paper\\Mine\\Paper3\\Properties.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "# Select the values from row 3 and onwards\n",
    "Properties = df.values[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161ba44f-9042-495b-85be-b3a447fa6baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assume the data array is already loaded into a variable named 'data'\n",
    "\n",
    "# Find the indices where the values are \"N\" or \"F\"\n",
    "idx_n = np.where(Properties == np.array([\"N\"], dtype=str))\n",
    "idx_f = np.where(Properties == np.array([\"F\"], dtype=str))\n",
    "\n",
    "# Replace \"N\" with \"1\"\n",
    "Properties[idx_n] = 1\n",
    "\n",
    "# Replace \"F\" with \"2\"\n",
    "Properties[idx_f] = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2ae10c-103c-40a0-b19f-c53e9b7174ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Properties = np.array(Properties)\n",
    "Properties = Properties.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0cf142-7dab-4ee7-b0b2-da163ac2e4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resulotion = 0.1\n",
    "Dim = round((Properties[-1,0]-Properties[0,0])/resulotion)\n",
    "Properties_res = np.zeros((Dim, Properties.shape[1]))\n",
    "Data_res = np.zeros((len(txt_files), Dim, Data.shape[2]))\n",
    "t0 = 5\n",
    "tf = 620.8\n",
    "t = t0\n",
    "Data_inter = np.zeros(len(txt_files),dtype=\"int\")\n",
    "Properties_inter = 0\n",
    "#for j in range(len(txt_files)):\n",
    "for j in range(1):\n",
    "    for i in range(Data[j].shape[0]):\n",
    "        if Data[j,i,0] >= t0:\n",
    "            Data_inter[j] = i - 1\n",
    "            break\n",
    "for i in range(Dim):\n",
    "    Properties_res[i] = Properties[Properties_inter]\n",
    "    Properties_res[i,0] = t\n",
    "    if t >= Properties[Properties_inter+1,0]:\n",
    "        Properties_inter += 1\n",
    "    for j in range(len(txt_files)):\n",
    "        if Data[j,Data_inter[j]+2,0]==0:\n",
    "            continue\n",
    "        Data_res[j,i] = Data[j, Data_inter[j]]\n",
    "        Data_res[j,i,0] = t\n",
    "        while True:\n",
    "            if t >= Data[j, Data_inter[j] + 1,0]:\n",
    "                Data_inter[j] += 1\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    t += resulotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba492aed-8466-44e4-8044-1f70123c452b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number 1\n",
    "XBminN1 = 120 #X Body min Near\n",
    "XBmaxN1 = 160 #X Body max Near\n",
    "\n",
    "XBminF1 = 150 #X Body min Far\n",
    "XBmaxF1 = 170 #X Body max Far\n",
    "\n",
    "\n",
    "# Number 2\n",
    "XBminN2 = 160 #X Body min Near\n",
    "XBmaxN2 = 195 #X Body max Near\n",
    "\n",
    "XBminF2 = 170 #X Body min Far\n",
    "XBmaxF2 = 190 #X Body max Far\n",
    "\n",
    "\n",
    "# Number 3\n",
    "XBminN3 = 195 #X Body min Near\n",
    "XBmaxN3 = 230 #X Body max Near\n",
    "\n",
    "XBminF3 = 190 #X Body min Far\n",
    "XBmaxF3 = 220 #X Body max Far\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da603ec5-6753-438c-b152-b093fabee43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data = np.zeros((Data_res.shape[0]*Data_res.shape[1],Properties_res.shape[1]))\n",
    "Model_label = np.zeros((Data_res.shape[0]*Data_res.shape[1]), dtype=\"O\")\n",
    "inter = 0\n",
    "for z in range(Data_res.shape[0]):\n",
    "    for j in range(Data_res.shape[1]):\n",
    "        if Data_res[z,j,0] == 0:\n",
    "            continue\n",
    "        Model_data[inter] = Properties_res[j]\n",
    "        Model_label[inter] = \"No Data\"\n",
    "\n",
    "        P = 0 # number of person 1\n",
    "        if Properties_res[j,6*P+1] == 1: #if the person is present\n",
    "            if Properties_res[j,6*P+2] == 1: #if the person is Near or Far\n",
    "                if Properties_res[j,6*P+3] != 7: #if the person is stationary or Entering or Leaving\n",
    "                    if XBminN1<Data_res[z,j,2]<XBmaxN1: #Body\n",
    "                        Model_label[inter] = \"Number 1\"\n",
    "                            \n",
    "                elif Properties_res[j,6*P+3] == 7:  #if the person is stationary or moving\n",
    "                    if 100<Data_res[z,j,2]<XBmaxN1: #Body\n",
    "                        Model_label[inter] = \"Number 1\"\n",
    "\n",
    "                        \n",
    "            elif Properties_res[j,6*P+2] == 2: #if the person is Near or Far\n",
    "                if Properties_res[j,6*P+3] != 7: #if the person is stationary or Entering or Leaving\n",
    "                    if XBminF1<Data_res[z,j,2]<XBmaxF1: #Body\n",
    "                        Model_label[inter] = \"Number 1\"\n",
    "\n",
    "                elif Properties_res[j,6*P+3] == 7:  #if the person is stationary or moving\n",
    "                    if 100<Data_res[z,j,2]<XBmaxN1: #Body\n",
    "                        Model_label[inter] = \"Number 1\"\n",
    "\n",
    "\n",
    "        P = 1 # number of person 2\n",
    "        if Properties_res[j,6*P+1] == 1: #if the person is present\n",
    "            if Properties_res[j,6*P+2] == 1: #if the person is Near or Far\n",
    "                if Properties_res[j,6*P+3] != 7: #if the person is stationary or Entering or Leaving\n",
    "                    if XBminN2<Data_res[z,j,2]<XBmaxN2: #Body\n",
    "                        Model_label[inter] = \"Number 2\"\n",
    "                            \n",
    "                elif Properties_res[j,6*P+3] == 7:  #if the person is stationary or moving\n",
    "                    if Properties_res[j,6*P+6] <=0:  #if the person is leaving or entering from left side\n",
    "                        if 100<Data_res[z,j,2]<180: #Body\n",
    "                            Model_label[inter] = \"Number 2\"\n",
    "                    elif Properties_res[j,6*P+6] >=0:  #if the person is leaving or entering from left side\n",
    "                        if 180<Data_res[z,j,2]<250: #Body\n",
    "                            Model_label[inter] = \"Number 2\"\n",
    "                            \n",
    "\n",
    "            elif Properties_res[j,6*P+2] == 2: #if the person is Near or Far\n",
    "                if Properties_res[j,6*P+3] != 7: #if the person is stationary or Entering or Leaving\n",
    "                    if XBminF2<Data_res[z,j,2]<XBmaxF2: #Body\n",
    "                        Model_label[inter] = \"Number 2\"\n",
    "\n",
    "                            \n",
    "                elif Properties_res[j,6*P+3] == 7:  #if the person is stationary or moving\n",
    "                    if Properties_res[j,6*P+6] <=0:  #if the person is leaving or entering from left side\n",
    "                        if 100<Data_res[z,j,2]<180: #Body\n",
    "                            Model_label[inter] = \"Number 2\"\n",
    "                    elif Properties_res[j,6*P+6] >=0:  #if the person is leaving or entering from left side\n",
    "                        if 180<Data_res[z,j,2]<250: #Body\n",
    "                            Model_label[inter] = \"Number 2\"\n",
    "                            \n",
    "\n",
    "        P = 2 # number of person 3\n",
    "        if Properties_res[j,6*P+1] == 1: #if the person is present\n",
    "            if Properties_res[j,6*P+2] == 1: #if the person is Near or Far\n",
    "                if Properties_res[j,6*P+3] != 7: #if the person is stationary or Entering or Leaving\n",
    "                    if XBminN3<Data_res[z,j,2]<XBmaxN3: #Body\n",
    "                        Model_label[inter] = \"Number 3\"\n",
    "                            \n",
    "                elif Properties_res[j,6*P+3] == 7:  #if the person is stationary or moving\n",
    "                    if XBminN3<Data_res[z,j,2]<250: #Body\n",
    "                        Model_label[inter] = \"Number 3\"\n",
    "\n",
    "            elif Properties_res[j,6*P+2] == 2: #if the person is Near or Far\n",
    "                if Properties_res[j,6*P+3] != 7: #if the person is stationary or Entering or Leaving\n",
    "                    if XBminF3<Data_res[z,j,2]<XBmaxF3: #Body\n",
    "                        Model_label[inter] = \"Number 3\"\n",
    "                        \n",
    "                elif Properties_res[j,6*P+3] == 7:  #if the person is stationary or moving\n",
    "                        if XBminF3<Data_res[z,j,2]<250: #Body\n",
    "                            Model_label[inter] = \"Number 3\"\n",
    "        inter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80eba4f-7d60-43a3-af0b-37ec397c38d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data = np.array(Model_data[0:inter])\n",
    "Model_label = np.array(Model_label[0:inter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1e033a-1e96-409c-a3e1-931b71eed39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65625, 19)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad3c4f3-2735-43d6-b2a2-0082814fa13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(Model_data)\n",
    "Model_data_normal = scaler.transform(Model_data)  #scale the data\n",
    "\n",
    "Model_data_normal = np.delete(Model_data_normal, [0,1,7,13], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b79775-98d7-41e2-bfdc-074707eb067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Labell(String):\n",
    "    if String == \"Number 1\":\n",
    "        return 0\n",
    "    elif String == \"Number 2\":\n",
    "        return 1\n",
    "    elif String == \"Number 3\":\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef641898-5a96-44aa-a6a4-bf337368b7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model_data_normal_sequence = np.zeros((Model_data_normal.shape[0]-sequence+1,sequence,Model_data_normal.shape[1]),dtype='float')\n",
    "# for i in range(Model_data_normal_sequence.shape[0]):\n",
    "#     for j in range(sequence):\n",
    "#         Model_data_normal_sequence[i,j] = Model_data_normal[i+j]\n",
    "        \n",
    "# Model_data_normal_sequence = np.delete(Model_data_normal_sequence, -1, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499c5e1a-9d33-4a97-a22e-6513c9b04581",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data_normal_sequence = np.zeros((Model_data_normal.shape[0],sequence,Model_data_normal.shape[1]),dtype='float')\n",
    "Model_label_sequence = np.zeros((Model_data_normal.shape[0],1),dtype='int')\n",
    "inter = 0\n",
    "Persons_inter = np.zeros(len(txt_files))\n",
    "inter2 = 0\n",
    "for i in range(Model_data_normal_sequence.shape[0]-sequence):\n",
    "    if Model_data[i, 0] == 5:\n",
    "        Persons_inter[inter2] = inter\n",
    "        inter2 += 1\n",
    "    if Model_label[i+sequence] != \"No Data\" and (Model_data[i+sequence, 0] - Model_data[i, 0]) > 0:\n",
    "        Model_label_sequence[inter] = Labell(Model_label[i+sequence])\n",
    "        for j in range(sequence):\n",
    "            Model_data_normal_sequence[inter,j] = Model_data_normal[i+j]\n",
    "        inter += 1\n",
    "        \n",
    "Model_data_normal_sequence = np.array(Model_data_normal_sequence[0:inter])\n",
    "Model_label_sequence = np.array(Model_label_sequence[0:inter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8d8353-5505-403e-a423-af444f33ac0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0.,  3410.,  9221., 14468., 19528., 25504., 31464., 37475.,\n",
       "       42630., 48598., 54177.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Persons_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8b3e77-bba3-4d56-8be5-7f6cd9b9a0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59918, 30, 15)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_data_normal_sequence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e3a272-ff26-4546-837f-475d6ca48fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(Model_data_normal_sequence[int(Persons_inter[Size]):Model_data_normal_sequence.shape[0]])\n",
    "train_label = np.array(Model_label_sequence[int(Persons_inter[Size]):Model_label_sequence.shape[0]])\n",
    "test_data = np.array(Model_data_normal_sequence[0:int(Persons_inter[Size])])\n",
    "test_label = np.array(Model_label_sequence[0:int(Persons_inter[Size])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aa04f3-1d57-4295-bfe3-d5f52900198e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data: (50697, 30, 15)\n",
      "train_label: (50697, 1)\n",
      "test_data: (9221, 30, 15)\n",
      "test_label: (9221, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_data:\",train_data.shape)\n",
    "print(\"train_label:\",train_label.shape)\n",
    "print(\"test_data:\",test_data.shape)\n",
    "print(\"test_label:\",test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49818b38-8a43-4956-a61d-2b68cab69f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "#X_train = train_data.reshape(train_data.shape[0],sequence, -1)\n",
    "one_hot_encoded_labels_train = to_categorical(train_label)\n",
    "\n",
    "#X_test = test_data.reshape(test_data.shape[0],sequence, -1)\n",
    "one_hot_encoded_labels_test = to_categorical(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849e4ad8-44ce-4d73-a636-b2843d63005c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 30, 64)            20480     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 53,699\n",
      "Trainable params: 53,699\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(lstm1, activation='tanh',input_shape=(train_data.shape[1],train_data.shape[2]), return_sequences= True))\n",
    "model.add(LSTM(lstm2, activation='tanh',input_shape=(train_data.shape[1],train_data.shape[2]), return_sequences= False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(one_hot_encoded_labels_train[0].shape[0], activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807c72ac-4103-488c-911f-48b1e1e4faaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2535/2535 [==============================] - 76s 28ms/step - loss: 0.6278 - accuracy: 0.7145 - val_loss: 0.6368 - val_accuracy: 0.7111\n"
     ]
    }
   ],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor = 'val_accuracy', patience = early, mode = 'max', restore_best_weights = True)\n",
    "import keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import schedules\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
    "\n",
    "model_training_history = model.fit(x = train_data, y = one_hot_encoded_labels_train, epochs = 1 , batch_size = 20,\n",
    "                                                    shuffle = True, validation_data=(test_data, one_hot_encoded_labels_test),\n",
    "                                                    callbacks = [early_stopping_callback])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c9f742-a2e6-454c-b95e-ea6cfddca577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1585/1585 [==============================] - 20s 12ms/step\n",
      "289/289 [==============================] - 3s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = model.predict(train_data)\n",
    "y_pred_test = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa00c41b-1b94-4726-9cb7-96a465fbc864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracymodel1(y_pred,train_label):\n",
    "    SumCorrect = 0\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        a = np.array(y_pred[i])\n",
    "        a = a.argmax()\n",
    "        if a==train_label[i,0]:\n",
    "            SumCorrect = SumCorrect + 1\n",
    "    return SumCorrect/y_pred.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff19438f-68e1-4e9a-b88f-3a117935a5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7110942414054875"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracymodel1(y_pred_train,train_label)\n",
    "accuracymodel1(y_pred_test,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0b84b4-deb7-4f2f-a7ca-c3eb915fccc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracymodel2(y_pred,train_label):\n",
    "    SumCorrect = 0\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        a = np.array(y_pred[i])\n",
    "        b = np.array(y_pred[i])\n",
    "        a = a.argmax()\n",
    "        b[a] = 0\n",
    "        b = b.argmax()\n",
    "        \n",
    "        if a==train_label[i,0] or b==train_label[i,0]:\n",
    "            SumCorrect = SumCorrect + 1\n",
    "    return SumCorrect/y_pred.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942eee0b-daa1-423f-858c-bfaf1d90e6bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9466435310703828"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracymodel2(y_pred_train,train_label)\n",
    "accuracymodel2(y_pred_test,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120d943b-ad8a-4673-a4cf-40aeb131690d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracymodel3(y_pred,train_label):\n",
    "    SumCorrect = 0\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        a = np.array(y_pred[i])\n",
    "        b = np.array(y_pred[i])\n",
    "        c = np.array(y_pred[i])\n",
    "        a = a.argmax()\n",
    "        b[a] = 0\n",
    "        b = b.argmax()\n",
    "        c[a] = 0\n",
    "        c[b] = 0\n",
    "        c = c.argmax()\n",
    "        \n",
    "        if a==train_label[i,0] or b==train_label[i,0] or c==train_label[i,0]:\n",
    "            SumCorrect = SumCorrect + 1\n",
    "    return SumCorrect/y_pred.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c157b25-c290-4d5b-9f3e-f8714bd92fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracymodel3(y_pred_train,train_label)\n",
    "accuracymodel3(y_pred_test,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac07b89-e94d-4253-b808-dded573b52b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = np.array([[accuracymodel1(y_pred_train,train_label), accuracymodel2(y_pred_train,train_label),accuracymodel3(y_pred_train,train_label)],\n",
    "#              [accuracymodel1(y_pred_test,test_label), accuracymodel2(y_pred_test,test_label),accuracymodel3(y_pred_test,test_label)]])\n",
    "# print(A)\n",
    "# Name = \"LSTMBody-K\"+str(K)+\"-NTD\"+str(NTD)+\"-sequence\" +str(sequence)+\"-delta\"+str(delta)\n",
    "# np.savetxt(r\"F:\\Courses\\Paper\\Mine\\New\\Process\\Result\\Real\\Olds\\Results\"+\"/\"+Name+'.csv', A, delimiter=',')   # X is an array\n",
    "# model.save(r\"F:\\Courses\\Paper\\Mine\\New\\Process\\Result\\Real\\Olds\\Results\"+\"/\"+Name+'.h5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9934cf-3fa0-4f0a-9b6e-23e9d839fe13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
