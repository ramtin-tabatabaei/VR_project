{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22511e53-1781-4b0d-ada0-31203fb3b454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d919ad22-670b-4033-9db0-e1464ef2fe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "sequence = 30\n",
    "delta = 1\n",
    "K_max = 10 # Training = 1:NTD & Test = NTD:12\n",
    "K = 3\n",
    "epoch = 100\n",
    "early = 10\n",
    "lstm1 = 64\n",
    "lstm2 = 64\n",
    "random = 0 # on=1 off=0\n",
    "KFold = 1 # on=1 off=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5a2b309-d795-44fc-b362-407edfd7e3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of txt files: 15\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "directory = r\"/Users/stabatabaeim/Downloads/Data\"  \n",
    "\n",
    "# get a list of all .txt files in the directory\n",
    "txt_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.txt')]\n",
    "\n",
    "# print the number of .txt files found\n",
    "print(\"Number of txt files:\", len(txt_files))\n",
    "\n",
    "# read the contents of each .txt file and store them in an array\n",
    "Data = np.zeros((len(txt_files),50000,4))\n",
    "for file_path in txt_files:\n",
    "    for i in range(len(txt_files)):\n",
    "        data = np.loadtxt(txt_files[i], dtype=object)\n",
    "        data = [line.split(',') for line in data]\n",
    "\n",
    "        # Convert the resulting list of lists to a NumPy array with the appropriate data types\n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        #data = data.astype(np.int32)\n",
    "        A = np.zeros((50000-data.shape[0], data.shape[1]))\n",
    "        Data[i] = np.concatenate((data, A))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eabacbb9-95f9-4a5c-b786-5ac0835ef5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 50000, 4)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02f99ce9-29c2-4157-8c9d-bcd69fb5755e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if KFold == 1:\n",
    "#     Size = round(len(txt_files)*(1-TTP))\n",
    "#     print(\"Size: \",Size)\n",
    "#     data_zeros = np.zeros((Data.shape[0], Data.shape[1], Data.shape[2]),dtype='float') \n",
    "#     startpoint = (K-1)*Size\n",
    "#     A = np.array(range(len(txt_files)))\n",
    "#     for i in range(Size):\n",
    "#         data_zeros[i] = Data[startpoint]\n",
    "#         A = np.delete(A, Size*(K-1))\n",
    "#         startpoint = startpoint + 1\n",
    "#     for i in range(len(txt_files)-Size):\n",
    "#         data_zeros[i+Size] = Data[A[i]]\n",
    "#     Data = data_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "888b812a-cf76-4592-a1b1-ef72dfe30009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file into a DataFrame\n",
    "df = pd.read_excel(r\"/Users/stabatabaeim/Downloads/Properties.xlsx\", sheet_name='Sheet1')\n",
    "\n",
    "# Select the values from row 3 and onwards\n",
    "Properties = df.values[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "161ba44f-9042-495b-85be-b3a447fa6baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assume the data array is already loaded into a variable named 'data'\n",
    "\n",
    "# Find the indices where the values are \"N\" or \"F\"\n",
    "idx_n = np.where(Properties == np.array([\"N\"], dtype=str))\n",
    "idx_f = np.where(Properties == np.array([\"F\"], dtype=str))\n",
    "\n",
    "# Replace \"N\" with \"1\"\n",
    "Properties[idx_n] = 1\n",
    "\n",
    "# Replace \"F\" with \"2\"\n",
    "Properties[idx_f] = 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed2ae10c-103c-40a0-b19f-c53e9b7174ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Properties = np.array(Properties)\n",
    "Properties = Properties.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d340db98-531e-4b8a-bb0e-988b3b68ac8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175, 19)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Properties.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7278d42d-1949-4de4-a405-8b6c8058bc46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5.,   1.,   1.,   7.,   0.,   0., -75.,   1.,   2.,   7.,   0.,\n",
       "         0.,  60.,   0.,   0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Properties[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "af0cf142-7dab-4ee7-b0b2-da163ac2e4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resulotion = 0.1\n",
    "Dim = round((Properties[-1,0]-Properties[0,0])/resulotion)\n",
    "Properties_res = np.zeros((Dim, Properties.shape[1]))\n",
    "Data_res = np.zeros((len(txt_files), Dim, Data.shape[2]))\n",
    "t0 = 5\n",
    "tf = 620.8\n",
    "t = t0\n",
    "Data_inter = np.zeros(len(txt_files),dtype=\"int\")\n",
    "Properties_inter = 0\n",
    "#for j in range(len(txt_files)):\n",
    "for j in range(1):\n",
    "    for i in range(Data[j].shape[0]):\n",
    "        if Data[j,i,0] >= t0:\n",
    "            Data_inter[j] = i - 1\n",
    "            break\n",
    "for i in range(Dim):\n",
    "    Properties_res[i] = Properties[Properties_inter]\n",
    "    Properties_res[i,0] = t\n",
    "    if t >= Properties[Properties_inter+1,0]:\n",
    "        Properties_inter += 1\n",
    "    for j in range(len(txt_files)):\n",
    "        if Data[j,Data_inter[j]+2,0]==0:\n",
    "            continue\n",
    "        Data_res[j,i] = Data[j, Data_inter[j]]\n",
    "        Data_res[j,i,0] = t\n",
    "        while True:\n",
    "            if t >= Data[j, Data_inter[j] + 1,0]:\n",
    "                Data_inter[j] += 1\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    t += resulotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e20020d2-dbf0-488c-a9c3-2ad412f4093c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 6158, 4)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "87134e74-5fb9-4ad2-b760-cd01c50ce5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127,)\n",
      "131.49\n",
      "192.19\n"
     ]
    }
   ],
   "source": [
    "Sit_change = []\n",
    "Sit_change.append(-1)\n",
    "array_without_angle_col = np.delete(Properties_res, [0,6,12,18], axis=1)\n",
    "for i in range(Properties_res.shape[0]-1):\n",
    "    if not np.array_equal(array_without_angle_col[i+1], array_without_angle_col[i]):\n",
    "        Sit_change.append(i)\n",
    "        \n",
    "Sit_change.append(tf/resulotion)\n",
    "Sit_change = np.array(Sit_change)\n",
    "print(Sit_change.shape)\n",
    "target_number = int(K/resulotion*tf/K_max)\n",
    "nearest_index = np.abs(Sit_change - target_number).argmin()\n",
    "Stop_K = int(Sit_change[nearest_index] + 1)\n",
    "Stop_t = int(Properties_res[Stop_K,0]*100)/100\n",
    "\n",
    "target_number = int((K-1)/resulotion*tf/K_max)\n",
    "nearest_index = np.abs(Sit_change - target_number).argmin()\n",
    "Start_K = int(Sit_change[nearest_index] + 1)\n",
    "Start_t = int(Properties_res[Start_K,0]*100)/100\n",
    "print(Start_t)\n",
    "print(Stop_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f77bc2ec-b102-4918-9ca9-7b47040282b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189.19"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stop_t-resulotion*sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "be1c7d47-5ca7-4901-beab-d66884fb7feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  -1,   53,  101,  150,  200,  254,  300,  323,  355,  403,  457,\n",
       "        505,  555,  608,  657,  713,  757,  811,  860,  910,  961, 1011,\n",
       "       1061, 1114, 1171, 1211, 1264, 1314, 1368, 1416, 1467, 1517, 1566,\n",
       "       1619, 1668, 1720, 1771, 1823, 1871, 1919, 1971, 2021, 2072, 2123,\n",
       "       2174, 2221, 2274, 2326, 2377, 2429, 2466, 2529, 2578, 2628, 2681,\n",
       "       2729, 2751, 2766, 2831, 2881, 2931, 2983, 3035, 3085, 3093, 3135,\n",
       "       3182, 3231, 3287, 3335, 3388, 3440, 3493, 3540, 3590, 3640, 3689,\n",
       "       3740, 3792, 3852, 3895, 3994, 4011, 4042, 4095, 4147, 4197, 4244,\n",
       "       4291, 4344, 4395, 4445, 4501, 4550, 4600, 4650, 4698, 4750, 4802,\n",
       "       4850, 4901, 4954, 5004, 5057, 5103, 5153, 5205, 5223, 5254, 5308,\n",
       "       5359, 5403, 5456, 5506, 5525, 5557, 5610, 5662, 5712, 5760, 5810,\n",
       "       5860, 5918, 5963, 6013, 6122, 6207])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(Sit_change, dtype ='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ba492aed-8466-44e4-8044-1f70123c452b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number 1\n",
    "XBminN1 = 120 #X Body min Near\n",
    "XBmaxN1 = 160 #X Body max Near\n",
    "\n",
    "XBminF1 = 150 #X Body min Far\n",
    "XBmaxF1 = 170 #X Body max Far\n",
    "\n",
    "\n",
    "# Number 2\n",
    "XBminN2 = 160 #X Body min Near\n",
    "XBmaxN2 = 195 #X Body max Near\n",
    "\n",
    "XBminF2 = 170 #X Body min Far\n",
    "XBmaxF2 = 190 #X Body max Far\n",
    "\n",
    "\n",
    "# Number 3\n",
    "XBminN3 = 195 #X Body min Near\n",
    "XBmaxN3 = 230 #X Body max Near\n",
    "\n",
    "XBminF3 = 190 #X Body min Far\n",
    "XBmaxF3 = 220 #X Body max Far\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da603ec5-6753-438c-b152-b093fabee43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data = np.zeros((Data_res.shape[0]*Data_res.shape[1],Properties_res.shape[1]))\n",
    "Model_label = np.zeros((Data_res.shape[0]*Data_res.shape[1]), dtype=\"O\")\n",
    "inter = 0\n",
    "for z in range(Data_res.shape[0]):\n",
    "    for j in range(Data_res.shape[1]):\n",
    "        if Data_res[z,j,0] == 0:\n",
    "            continue\n",
    "        Model_data[inter] = Properties_res[j]\n",
    "        Model_label[inter] = \"No Data\"\n",
    "\n",
    "        P = 0 # number of person 1\n",
    "        if Properties_res[j,6*P+1] == 1: #if the person is present\n",
    "            if Properties_res[j,6*P+2] == 1: #if the person is Near or Far\n",
    "                if Properties_res[j,6*P+3] != 7: #if the person is stationary or Entering or Leaving\n",
    "                    if XBminN1<Data_res[z,j,2]<XBmaxN1: #Body\n",
    "                        Model_label[inter] = \"Number 1\"\n",
    "                            \n",
    "                elif Properties_res[j,6*P+3] == 7:  #if the person is stationary or moving\n",
    "                    if 100<Data_res[z,j,2]<XBmaxN1: #Body\n",
    "                        Model_label[inter] = \"Number 1\"\n",
    "\n",
    "                        \n",
    "            elif Properties_res[j,6*P+2] == 2: #if the person is Near or Far\n",
    "                if Properties_res[j,6*P+3] != 7: #if the person is stationary or Entering or Leaving\n",
    "                    if XBminF1<Data_res[z,j,2]<XBmaxF1: #Body\n",
    "                        Model_label[inter] = \"Number 1\"\n",
    "\n",
    "                elif Properties_res[j,6*P+3] == 7:  #if the person is stationary or moving\n",
    "                    if 100<Data_res[z,j,2]<XBmaxN1: #Body\n",
    "                        Model_label[inter] = \"Number 1\"\n",
    "\n",
    "\n",
    "        P = 1 # number of person 2\n",
    "        if Properties_res[j,6*P+1] == 1: #if the person is present\n",
    "            if Properties_res[j,6*P+2] == 1: #if the person is Near or Far\n",
    "                if Properties_res[j,6*P+3] != 7: #if the person is stationary or Entering or Leaving\n",
    "                    if XBminN2<Data_res[z,j,2]<XBmaxN2: #Body\n",
    "                        Model_label[inter] = \"Number 2\"\n",
    "                            \n",
    "                elif Properties_res[j,6*P+3] == 7:  #if the person is stationary or moving\n",
    "                    if Properties_res[j,6*P+6] <=0:  #if the person is leaving or entering from left side\n",
    "                        if 100<Data_res[z,j,2]<180: #Body\n",
    "                            Model_label[inter] = \"Number 2\"\n",
    "                    elif Properties_res[j,6*P+6] >=0:  #if the person is leaving or entering from left side\n",
    "                        if 180<Data_res[z,j,2]<250: #Body\n",
    "                            Model_label[inter] = \"Number 2\"\n",
    "                            \n",
    "\n",
    "            elif Properties_res[j,6*P+2] == 2: #if the person is Near or Far\n",
    "                if Properties_res[j,6*P+3] != 7: #if the person is stationary or Entering or Leaving\n",
    "                    if XBminF2<Data_res[z,j,2]<XBmaxF2: #Body\n",
    "                        Model_label[inter] = \"Number 2\"\n",
    "\n",
    "                            \n",
    "                elif Properties_res[j,6*P+3] == 7:  #if the person is stationary or moving\n",
    "                    if Properties_res[j,6*P+6] <=0:  #if the person is leaving or entering from left side\n",
    "                        if 100<Data_res[z,j,2]<180: #Body\n",
    "                            Model_label[inter] = \"Number 2\"\n",
    "                    elif Properties_res[j,6*P+6] >=0:  #if the person is leaving or entering from left side\n",
    "                        if 180<Data_res[z,j,2]<250: #Body\n",
    "                            Model_label[inter] = \"Number 2\"\n",
    "                            \n",
    "\n",
    "        P = 2 # number of person 3\n",
    "        if Properties_res[j,6*P+1] == 1: #if the person is present\n",
    "            if Properties_res[j,6*P+2] == 1: #if the person is Near or Far\n",
    "                if Properties_res[j,6*P+3] != 7: #if the person is stationary or Entering or Leaving\n",
    "                    if XBminN3<Data_res[z,j,2]<XBmaxN3: #Body\n",
    "                        Model_label[inter] = \"Number 3\"\n",
    "                            \n",
    "                elif Properties_res[j,6*P+3] == 7:  #if the person is stationary or moving\n",
    "                    if XBminN3<Data_res[z,j,2]<250: #Body\n",
    "                        Model_label[inter] = \"Number 3\"\n",
    "\n",
    "            elif Properties_res[j,6*P+2] == 2: #if the person is Near or Far\n",
    "                if Properties_res[j,6*P+3] != 7: #if the person is stationary or Entering or Leaving\n",
    "                    if XBminF3<Data_res[z,j,2]<XBmaxF3: #Body\n",
    "                        Model_label[inter] = \"Number 3\"\n",
    "                        \n",
    "                elif Properties_res[j,6*P+3] == 7:  #if the person is stationary or moving\n",
    "                        if XBminF3<Data_res[z,j,2]<250: #Body\n",
    "                            Model_label[inter] = \"Number 3\"\n",
    "        inter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b80eba4f-7d60-43a3-af0b-37ec397c38d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data = np.array(Model_data[0:inter])\n",
    "Model_label = np.array(Model_label[0:inter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2d1e033a-1e96-409c-a3e1-931b71eed39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90257, 19)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0ad3c4f3-2735-43d6-b2a2-0082814fa13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(Model_data)\n",
    "Model_data_normal = scaler.transform(Model_data)  #scale the data\n",
    "\n",
    "Model_data_normal = np.delete(Model_data_normal, 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c4fcabc7-1d78-472c-b02f-c5fab73b2ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = scaler.mean_\n",
    "std = scaler.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "48a9453b-46fd-4ce0-b819-2e84ed7a737e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.8220969    1.23059707   3.93203851   0.30711191   0.06636604\n",
      " -31.7745992    0.8045581    1.19866603   3.77597305   0.28457627\n",
      "   0.16342223  -0.37476318   0.81636881   1.22212128   3.61347042\n",
      "   0.24680634   0.07481968  31.26738092]\n",
      "[ 0.38243115  0.7302248   2.76653838  0.4612962   0.24892085 17.26125689\n",
      "  0.3965405   0.74167489  2.72222473  0.45121238  0.3941179  10.20974981\n",
      "  0.38718313  0.73487808  2.63858312  0.43115307  0.29298619 17.33424739]\n"
     ]
    }
   ],
   "source": [
    "print(mean[1:19])\n",
    "print(std[1:19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f9b79775-98d7-41e2-bfdc-074707eb067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Labell(String):\n",
    "    if String == \"Number 1\":\n",
    "        return 0\n",
    "    elif String == \"Number 2\":\n",
    "        return 1\n",
    "    elif String == \"Number 3\":\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ef641898-5a96-44aa-a6a4-bf337368b7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model_data_normal_sequence = np.zeros((Model_data_normal.shape[0]-sequence+1,sequence,Model_data_normal.shape[1]),dtype='float')\n",
    "# for i in range(Model_data_normal_sequence.shape[0]):\n",
    "#     for j in range(sequence):\n",
    "#         Model_data_normal_sequence[i,j] = Model_data_normal[i+j]\n",
    "        \n",
    "# Model_data_normal_sequence = np.delete(Model_data_normal_sequence, -1, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "499c5e1a-9d33-4a97-a22e-6513c9b04581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model_data_normal_sequence = np.zeros((Model_data_normal.shape[0],sequence,Model_data_normal.shape[1]),dtype='float')\n",
    "# Model_label_sequence = np.zeros((Model_data_normal.shape[0],1),dtype='int')\n",
    "# inter = 0\n",
    "# Persons_inter = np.zeros(len(txt_files))\n",
    "# inter2 = 0\n",
    "# for i in range(Model_data_normal_sequence.shape[0]-sequence):\n",
    "#     if Model_data[i, 0] == 5:\n",
    "#         Persons_inter[inter2] = inter\n",
    "#         inter2 += 1\n",
    "#     if Model_label[i+sequence] != \"No Data\" and (Model_data[i+sequence, 0] - Model_data[i, 0]) > 0:\n",
    "#         Model_label_sequence[inter] = Labell(Model_label[i+sequence])\n",
    "#         for j in range(sequence):\n",
    "#             Model_data_normal_sequence[inter,j] = Model_data_normal[i+j]\n",
    "#         inter += 1\n",
    "        \n",
    "# Model_data_normal_sequence = np.array(Model_data_normal_sequence[0:inter])\n",
    "# Model_label_sequence = np.array(Model_label_sequence[0:inter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0fd50879-db5b-409c-a604-b9b3d44c2001",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_normal_sequence = np.zeros((Model_data_normal.shape[0],sequence,Model_data_normal.shape[1]),dtype='float')\n",
    "train_label_sequence = np.zeros((Model_data_normal.shape[0],1),dtype='int')\n",
    "test_data_normal_sequence = np.zeros((Model_data_normal.shape[0],sequence,Model_data_normal.shape[1]),dtype='float')\n",
    "test_label_sequence = np.zeros((Model_data_normal.shape[0],1),dtype='int')\n",
    "train_inter = 0\n",
    "test_inter = 0\n",
    "for i in range(train_data_normal_sequence.shape[0]-sequence):\n",
    "    if Model_label[i+sequence] != \"No Data\" and (Model_data[i, 0] - Model_data[i-sequence, 0]) > 0:\n",
    "        if Model_data[i, 0]>=Start_t and Model_data[i, 0]<Stop_t-resulotion*sequence:\n",
    "            test_label_sequence[test_inter] = Labell(Model_label[i+sequence])\n",
    "            for j in range(sequence):\n",
    "                test_data_normal_sequence[test_inter,j] = Model_data_normal[i+j]\n",
    "            test_inter += 1\n",
    "                \n",
    "        elif Model_data[i, 0]<Start_t-resulotion*sequence:\n",
    "            train_label_sequence[train_inter] = Labell(Model_label[i+sequence])\n",
    "            for j in range(sequence):\n",
    "                train_data_normal_sequence[train_inter,j] = Model_data_normal[i+j]\n",
    "            train_inter += 1\n",
    "            \n",
    "        elif Model_data[i, 0]>=Stop_t and Model_data[i, 0]<tf-resulotion*sequence:\n",
    "            train_label_sequence[train_inter] = Labell(Model_label[i+sequence])\n",
    "            for j in range(sequence):\n",
    "                train_data_normal_sequence[train_inter,j] = Model_data_normal[i+j]\n",
    "            train_inter += 1\n",
    "\n",
    "train_data_normal_sequence = np.array(train_data_normal_sequence[0:train_inter])\n",
    "train_label_sequence = np.array(train_label_sequence[0:train_inter])\n",
    "test_data_normal_sequence = np.array(test_data_normal_sequence[0:test_inter])\n",
    "test_label_sequence = np.array(test_label_sequence[0:test_inter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2928a4c1-444b-46cd-a467-39b8ede23ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8246"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "538ea8e0-1046-46f9-9082-167abf0b733a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.859083191850594"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inter/test_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "98e3a272-ff26-4546-837f-475d6ca48fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(train_data_normal_sequence)\n",
    "train_label = np.array(train_label_sequence)\n",
    "test_data = np.array(test_data_normal_sequence)\n",
    "test_label = np.array(test_label_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b9aa04f3-1d57-4295-bfe3-d5f52900198e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data: (73052, 30, 18)\n",
      "train_label: (73052, 1)\n",
      "test_data: (8246, 30, 18)\n",
      "test_label: (8246, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_data:\",train_data.shape)\n",
    "print(\"train_label:\",train_label.shape)\n",
    "print(\"test_data:\",test_data.shape)\n",
    "print(\"test_label:\",test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "49818b38-8a43-4956-a61d-2b68cab69f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "#X_train = train_data.reshape(train_data.shape[0],sequence, -1)\n",
    "one_hot_encoded_labels_train = to_categorical(train_label,3)\n",
    "\n",
    "#X_test = test_data.reshape(test_data.shape[0],sequence, -1)\n",
    "one_hot_encoded_labels_test = to_categorical(test_label,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "849e4ad8-44ce-4d73-a636-b2843d63005c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">21,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m21,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54,467</span> (212.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m54,467\u001b[0m (212.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54,467</span> (212.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m54,467\u001b[0m (212.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(lstm1, activation='tanh',input_shape=(train_data.shape[1],train_data.shape[2]), return_sequences= True))\n",
    "model.add(LSTM(lstm2, activation='tanh',input_shape=(train_data.shape[1],train_data.shape[2]), return_sequences= False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(one_hot_encoded_labels_train[0].shape[0], activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "807c72ac-4103-488c-911f-48b1e1e4faaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m3653/3653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6972 - loss: 0.6584 - val_accuracy: 0.6659 - val_loss: 0.8484\n",
      "Epoch 2/10\n",
      "\u001b[1m3653/3653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.7359 - loss: 0.5878 - val_accuracy: 0.6607 - val_loss: 0.8595\n",
      "Epoch 3/10\n",
      "\u001b[1m 995/3653\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.7412 - loss: 0.5735"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m schedules\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 9\u001b[0m model_training_history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mone_hot_encoded_labels_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_hot_encoded_labels_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:325\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    324\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 325\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(\n\u001b[1;32m    327\u001b[0m         step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    328\u001b[0m     )\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor = 'val_accuracy', patience = early, mode = 'max', restore_best_weights = True)\n",
    "import keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import schedules\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
    "\n",
    "model_training_history = model.fit(x = train_data, y = one_hot_encoded_labels_train, epochs = 10 , batch_size = 20,\n",
    "                                                    shuffle = True, validation_data=(test_data, one_hot_encoded_labels_test),\n",
    "                                                    callbacks = [early_stopping_callback])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c9f742-a2e6-454c-b95e-ea6cfddca577",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model.predict(train_data)\n",
    "y_pred_test = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa00c41b-1b94-4726-9cb7-96a465fbc864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracymodel1(y_pred,train_label):\n",
    "    SumCorrect = 0\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        a = np.array(y_pred[i])\n",
    "        a = a.argmax()\n",
    "        if a==train_label[i,0]:\n",
    "            SumCorrect = SumCorrect + 1\n",
    "    return SumCorrect/y_pred.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff19438f-68e1-4e9a-b88f-3a117935a5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracymodel1(y_pred_train,train_label)\n",
    "accuracymodel1(y_pred_test,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0b84b4-deb7-4f2f-a7ca-c3eb915fccc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracymodel2(y_pred,train_label):\n",
    "    SumCorrect = 0\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        a = np.array(y_pred[i])\n",
    "        b = np.array(y_pred[i])\n",
    "        a = a.argmax()\n",
    "        b[a] = 0\n",
    "        b = b.argmax()\n",
    "        \n",
    "        if a==train_label[i,0] or b==train_label[i,0]:\n",
    "            SumCorrect = SumCorrect + 1\n",
    "    return SumCorrect/y_pred.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942eee0b-daa1-423f-858c-bfaf1d90e6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracymodel2(y_pred_train,train_label)\n",
    "accuracymodel2(y_pred_test,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120d943b-ad8a-4673-a4cf-40aeb131690d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracymodel3(y_pred,train_label):\n",
    "    SumCorrect = 0\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        a = np.array(y_pred[i])\n",
    "        b = np.array(y_pred[i])\n",
    "        c = np.array(y_pred[i])\n",
    "        a = a.argmax()\n",
    "        b[a] = 0\n",
    "        b = b.argmax()\n",
    "        c[a] = 0\n",
    "        c[b] = 0\n",
    "        c = c.argmax()\n",
    "        \n",
    "        if a==train_label[i,0] or b==train_label[i,0] or c==train_label[i,0]:\n",
    "            SumCorrect = SumCorrect + 1\n",
    "    return SumCorrect/y_pred.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c157b25-c290-4d5b-9f3e-f8714bd92fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracymodel3(y_pred_train,train_label)\n",
    "accuracymodel3(y_pred_test,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac07b89-e94d-4253-b808-dded573b52b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = np.array([[accuracymodel1(y_pred_train,train_label), accuracymodel2(y_pred_train,train_label),accuracymodel3(y_pred_train,train_label)],\n",
    "#              [accuracymodel1(y_pred_test,test_label), accuracymodel2(y_pred_test,test_label),accuracymodel3(y_pred_test,test_label)]])\n",
    "# print(A)\n",
    "# Name = \"LSTMBody-K\"+str(K)+\"-NTD\"+str(NTD)+\"-sequence\" +str(sequence)+\"-delta\"+str(delta)\n",
    "# np.savetxt(r\"F:\\Courses\\Paper\\Mine\\New\\Process\\Result\\Real\\Olds\\Results\"+\"/\"+Name+'.csv', A, delimiter=',')   # X is an array\n",
    "# model.save(r\"F:\\Courses\\Paper\\Mine\\New\\Process\\Result\\Real\\Olds\\Results\"+\"/\"+Name+'.h5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9934cf-3fa0-4f0a-9b6e-23e9d839fe13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
